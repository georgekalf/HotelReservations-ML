{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries for machine learning - predection analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# loading libraries for machine learning - predection analysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import os\n",
    "print(os.listdir())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the file\n",
    "hotel_df = pd.read_csv(\"/Users/georgekalfas/Downloads/ML-HotelReservations/EDA-ML/Hotel Reservations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model for Predicting Reservation Cancellation\n",
    "\n",
    "### Method Overview\n",
    "Logistic Regression is a statistical method used for predicting categorical outcomes. In the context of hotel reservation cancellations, it's applied to predict whether a customer will cancel their reservation or not.\n",
    "\n",
    "### Steps Involved:\n",
    "1. **Data Preparation**:\n",
    "   - **Feature Selection**: Identifying predictive features and the target variable (`booking_status`).\n",
    "   - **Encoding Categorical Variables**: Using label encoding to convert categorical variables into numerical format.\n",
    "   - **Splitting the Dataset**: Separating the dataset into training and testing sets to evaluate the model's performance.\n",
    "\n",
    "2. **Feature Standardization**:\n",
    "   - **Scaling Features**: Standardizing the features using `StandardScaler` to ensure uniformity in data distribution.\n",
    "\n",
    "3. **Logistic Regression Model**:\n",
    "   - **Model Creation**: Initializing and training the Logistic Regression model using the training dataset.\n",
    "\n",
    "4. **Model Evaluation**:\n",
    "   - **Predictions**: Making predictions on the test dataset.\n",
    "   - **Evaluation Metrics**: Assessing the model's performance using metrics like accuracy score, classification report, and confusion matrix.\n",
    "\n",
    "### Results:\n",
    "- **Accuracy Score**: The accuracy score obtained using Logistic Regression is displayed, indicating the model's overall predictive accuracy.\n",
    "- **Classification Report**: Provides detailed information on precision, recall, and F1-score for each class ('Canceled' and 'Not Canceled').\n",
    "- **Confusion Matrix**: Visual representation of predicted versus actual values to understand the model's performance.\n",
    "\n",
    "### Conclusion:\n",
    "Logistic Regression serves as an initial predictive model. The accuracy score and evaluation metrics help to understand its predictive capability in determining reservation cancellations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the target column for the predictions\n",
    "target_column = 'booking_status'\n",
    "\n",
    "# selecting features and target variable\n",
    "features = hotel_df.drop(target_column, axis=1) \n",
    "target = hotel_df[target_column]\n",
    "\n",
    "# handling categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in features.columns:\n",
    "    if features[column].dtype == 'object':\n",
    "        features[column] = label_encoder.fit_transform(features[column])\n",
    "\n",
    "# splitting the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# creating and train the Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# making the predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "lr_accuracy = accuracy_score(y_test, predictions) * 100\n",
    "print(f\"The accuracy score achieved using Logistic Regression is: {lr_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report for Logistic Regression:\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix for Logistic Regression:\")\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function for the confusion matrix\n",
    "def plot_confusion_matrix(conf_matrix, labels):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Define the class labels ('Not Canceled', 'Canceled')\n",
    "class_labels = ['Not Canceled', 'Canceled']\n",
    "\n",
    "# Plot the confusion matrix using the function\n",
    "plot_confusion_matrix(conf_matrix, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model for Predicting Reservation Cancellation\n",
    "\n",
    "### Method Overview\n",
    "Naive Bayes is a probabilistic machine learning method that uses Bayes' theorem to make predictions. In the context of hotel reservation cancellations, the Gaussian Naive Bayes classifier is employed to predict whether a customer will cancel their reservation or not.\n",
    "\n",
    "### Steps Involved:\n",
    "1. **Model Creation**:\n",
    "   - **Model Selection**: Using the Gaussian Naive Bayes model for training.\n",
    "   - **Training the Model**: Fitting the model using the training dataset.\n",
    "\n",
    "2. **Predictions and Evaluation**:\n",
    "   - **Making Predictions**: Using the trained model to make predictions on the test dataset.\n",
    "   - **Evaluation Metrics**: Assessing the model's performance using metrics like accuracy score, classification report, and confusion matrix.\n",
    "\n",
    "### Results:\n",
    "- **Accuracy Score**: The accuracy score obtained using the Naive Bayes model is displayed, representing the overall predictive accuracy.\n",
    "- **Classification Report**: Detailed metrics such as precision, recall, and F1-score for each class ('Canceled' and 'Not Canceled').\n",
    "- **Confusion Matrix**: Visualization of predicted versus actual values to assess the model's performance.\n",
    "\n",
    "### Conclusion:\n",
    "Naive Bayes, specifically the Gaussian variant, is applied for predictive analysis. The accuracy score and evaluation metrics provide insights into its effectiveness in predicting reservation cancellations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training the Naive Bayes (Gaussian) model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions using the trained model\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluating the Naive Bayes model\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions) * 100\n",
    "print(f\"The accuracy score achieved using Naive Bayes is: {nb_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report for Naive Bayes:\")\n",
    "print(classification_report(y_test, nb_predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix for Naive Bayes:\")\n",
    "print(confusion_matrix(y_test, nb_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, nb_predictions)\n",
    "\n",
    "# Define the class labels ('Not Canceled', 'Canceled')\n",
    "class_labels = ['Not Canceled', 'Canceled']\n",
    "\n",
    "# Plot the confusion matrix using the function\n",
    "plot_confusion_matrix(conf_matrix, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) for Reservation Cancellation Prediction\n",
    "\n",
    "### Method Overview\n",
    "Support Vector Machine is a powerful supervised learning algorithm used for classification tasks. In this analysis, SVM with various kernel functions (Linear, Polynomial, RBF) is applied to predict hotel reservation cancellations.\n",
    "\n",
    "### Steps Involved:\n",
    "1. **Linear Kernel SVM**:\n",
    "   - Model Creation: Using the SVM model with a linear kernel.\n",
    "   - Model Training: Fitting the SVM model using the training dataset.\n",
    "   - Predictions: Making predictions and evaluating the model using accuracy, classification report, and confusion matrix.\n",
    "\n",
    "2. **Polynomial Kernel SVM**:\n",
    "   - Model Creation: Employing the SVM model with a polynomial kernel (degree=3).\n",
    "   - Model Training: Fitting the SVM model to the training data.\n",
    "   - Predictions and Evaluation: Assessing accuracy and classification metrics.\n",
    "\n",
    "3. **RBF Kernel SVM**:\n",
    "   - Model Creation: Utilizing the SVM model with a radial basis function (RBF) kernel.\n",
    "   - Model Training: Fitting the SVM model with the RBF kernel to the training dataset.\n",
    "   - Predictions and Evaluation: Evaluating accuracy and classification performance.\n",
    "\n",
    "### Results:\n",
    "- **Accuracy Scores**: Displaying the accuracy achieved by SVM models with different kernels (Linear, Polynomial, RBF).\n",
    "- **Classification Reports**: Detailed metrics such as precision, recall, and F1-score for each class ('Canceled' and 'Not Canceled').\n",
    "- **Confusion Matrices**: Visualization of predicted versus actual values for assessing model performance.\n",
    "\n",
    "### Conclusion:\n",
    "SVM, with its various kernel functions, is employed for reservation cancellation prediction. The evaluation metrics aid in understanding the effectiveness of SVM with different kernels in this predictive task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear kernel\n",
    "svm_linear = SVC(kernel='linear', random_state=42)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "svm_linear_predictions = svm_linear.predict(X_test)\n",
    "\n",
    "svm_linear_accuracy = accuracy_score(y_test, svm_linear_predictions) * 100\n",
    "print(f\"The accuracy score achieved using SVM with Linear Kernel is: {svm_linear_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report for SVM with Linear Kernel:\")\n",
    "print(classification_report(y_test, svm_linear_predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix for SVM with Linear Kernel:\")\n",
    "print(confusion_matrix(y_test, svm_linear_predictions))\n",
    "\n",
    "# Polynomial kernel\n",
    "svm_poly = SVC(kernel='poly', degree=3, random_state=42)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "svm_poly_predictions = svm_poly.predict(X_test)\n",
    "\n",
    "svm_poly_accuracy = accuracy_score(y_test, svm_poly_predictions) * 100\n",
    "print(f\"\\nThe accuracy score achieved using SVM with Polynomial Kernel is: {svm_poly_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report for SVM with Polynomial Kernel:\")\n",
    "print(classification_report(y_test, svm_poly_predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix for SVM with Polynomial Kernel:\")\n",
    "print(confusion_matrix(y_test, svm_poly_predictions))\n",
    "\n",
    "# RBF kernel\n",
    "svm_rbf = SVC(kernel='rbf', random_state=42)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "svm_rbf_predictions = svm_rbf.predict(X_test)\n",
    "\n",
    "svm_rbf_accuracy = accuracy_score(y_test, svm_rbf_predictions) * 100\n",
    "print(f\"\\nThe accuracy score achieved using SVM with RBF Kernel is: {svm_rbf_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report for SVM with RBF Kernel:\")\n",
    "print(classification_report(y_test, svm_rbf_predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix for SVM with RBF Kernel:\")\n",
    "print(confusion_matrix(y_test, svm_rbf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining labels for confusion matrices\n",
    "labels = ['Not Canceled', 'Canceled']\n",
    "\n",
    "# Calculate confusion matrices\n",
    "conf_matrix_linear = confusion_matrix(y_test, svm_linear_predictions)\n",
    "conf_matrix_poly = confusion_matrix(y_test, svm_poly_predictions)\n",
    "conf_matrix_rbf = confusion_matrix(y_test, svm_rbf_predictions)\n",
    "\n",
    "# creating figure and axes\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# plotting confusion matrix for Linear Kernel\n",
    "sns.heatmap(conf_matrix_linear, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels, ax=axs[0])\n",
    "axs[0].set_title('SVM with Linear Kernel')\n",
    "\n",
    "# plotting confusion matrix for Polynomial Kernel\n",
    "sns.heatmap(conf_matrix_poly, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels, ax=axs[1])\n",
    "axs[1].set_title('SVM with Polynomial Kernel')\n",
    "\n",
    "# plotting confusion matrix for RBF Kernel\n",
    "sns.heatmap(conf_matrix_rbf, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels, ax=axs[2])\n",
    "axs[2].set_title('SVM with RBF Kernel')\n",
    "\n",
    "# displaying the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (KNN) for Reservation Cancellation Prediction\n",
    "\n",
    "### Method Overview\n",
    "K Nearest Neighbors is a versatile algorithm used for classification tasks based on feature similarity. In this analysis, KNN with 5 neighbors is applied to predict hotel reservation cancellations.\n",
    "\n",
    "### Steps Involved:\n",
    "1. **Model Creation and Training**:\n",
    "   - Creating KNN Model: Instantiating the K Nearest Neighbors model with 5 neighbors.\n",
    "   - Model Training: Training the KNN model using the provided training dataset.\n",
    "\n",
    "2. **Predictions and Evaluation**:\n",
    "   - Making Predictions: Generating predictions on the test dataset.\n",
    "   - Model Evaluation: Assessing model accuracy and classification metrics such as precision, recall, and F1-score.\n",
    "\n",
    "### Results:\n",
    "- **Accuracy Score**: Displaying the achieved accuracy by the KNN model.\n",
    "- **Classification Report**: Detailed classification metrics providing insights into model performance.\n",
    "- **Confusion Matrix**: Visualization depicting predicted versus actual values for evaluating model effectiveness.\n",
    "\n",
    "### Conclusion:\n",
    "K Nearest Neighbors, with its feature similarity-based classification approach, is employed for predicting reservation cancellations. The accuracy score and classification metrics help understand the model's predictive performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and training the K Nearest Neighbors (KNN) model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# making predictions using the trained KNN model\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "\n",
    "# evaluating the KNN model\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions) * 100\n",
    "print(f\"The accuracy score achieved using K Nearest Neighbors (KNN) is: {knn_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report for K Nearest Neighbors (KNN):\")\n",
    "print(classification_report(y_test, knn_predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix for K Nearest Neighbors (KNN):\")\n",
    "print(confusion_matrix(y_test, knn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, knn_predictions)\n",
    "\n",
    "# defining the class labels ('Not Canceled', 'Canceled')\n",
    "class_labels = ['Not Canceled', 'Canceled']\n",
    "\n",
    "# plotting the confusion matrix using the function\n",
    "plot_confusion_matrix(conf_matrix, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier for Reservation Cancellation Prediction\n",
    "\n",
    "### Method Overview\n",
    "Decision Tree Classifier is a tree-like model that makes decisions by splitting data based on feature values. In this analysis, a Decision Tree model is utilized to predict hotel reservation cancellations.\n",
    "\n",
    "### Steps Involved:\n",
    "1. **Hyperparameter Tuning**:\n",
    "   - Finding Best Parameters: Looping through various random states to determine the one that yields the highest accuracy.\n",
    "   - Model Instantiation: Creating a Decision Tree model with the best random state found.\n",
    "\n",
    "2. **Model Training and Prediction**:\n",
    "   - Model Training: Fitting the Decision Tree model using the training dataset.\n",
    "   - Generating Predictions: Using the trained model to predict reservation cancellations on the test dataset.\n",
    "\n",
    "3. **Evaluation**:\n",
    "   - Confusion Matrix: Computing the confusion matrix to analyze predicted versus actual results.\n",
    "\n",
    "### Results:\n",
    "- **Max Accuracy Achieved**: Displaying the highest accuracy attained by the Decision Tree model.\n",
    "- **Best Random State**: Identifying the random state that produced the most accurate predictions.\n",
    "- **Confusion Matrix**: Visualization illustrating the model's performance in predicting cancellation outcomes.\n",
    "\n",
    "### Conclusion:\n",
    "Decision Tree Classifier, through its branching structure based on features, is employed for predicting reservation cancellations. The analysis provides insights into model accuracy and its effectiveness in making cancellation predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_max_accuracy = 0\n",
    "best_x = 0\n",
    "\n",
    "for x in range(200):\n",
    "    dt = DecisionTreeClassifier(random_state=x)\n",
    "    dt.fit(X_train, y_train)\n",
    "    Y_pred_dt = dt.predict(X_test)\n",
    "    current_accuracy = round(accuracy_score(Y_pred_dt, y_test) * 100, 2)\n",
    "    if current_accuracy > dt_max_accuracy:\n",
    "        dt_max_accuracy = current_accuracy\n",
    "        best_x = x\n",
    "\n",
    "print(f\"Max accuracy achieved: {dt_max_accuracy}%\")\n",
    "print(f\"Best random state: {best_x}\")\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=best_x)\n",
    "dt.fit(X_train, y_train)\n",
    "Y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# computing confusion matrix\n",
    "cm = confusion_matrix(y_test, Y_pred_dt)\n",
    "print(\"\\nConfusion Matrix for Decision Tree Classifier:\")\n",
    "print(cm)\n",
    "\n",
    "# plotting confusion matrix\n",
    "plot_confusion_matrix(cm, ['Not Canceled', 'Canceled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier for Reservation Cancellation Prediction\n",
    "\n",
    "### Method Overview\n",
    "Random Forest Classifier is an ensemble learning technique that constructs multiple decision trees and merges their predictions to improve accuracy. In this analysis, Random Forest is employed for predicting hotel reservation cancellations.\n",
    "\n",
    "### Steps Involved:\n",
    "1. **Hyperparameter Tuning**:\n",
    "   - Finding Best Parameters: Iterating through different random states to identify the one yielding the highest accuracy.\n",
    "   - Model Initialization: Creating a Random Forest model with the best random state found.\n",
    "\n",
    "2. **Model Training and Prediction**:\n",
    "   - Model Fitting: Training the Random Forest model using the training dataset.\n",
    "   - Prediction Generation: Utilizing the trained model to predict reservation cancellations on the test dataset.\n",
    "\n",
    "3. **Evaluation**:\n",
    "   - Confusion Matrix: Computation of the confusion matrix to evaluate the model's predictive performance.\n",
    "\n",
    "### Results:\n",
    "- **Max Accuracy Achieved**: Displaying the highest accuracy attained by the Random Forest model.\n",
    "- **Best Random State**: Identifying the random state that produced the most accurate predictions.\n",
    "- **Confusion Matrix**: Visualization illustrating the model's performance in predicting cancellation outcomes.\n",
    "\n",
    "### Conclusion:\n",
    "Random Forest Classifier, by aggregating multiple decision trees, is used to predict hotel reservation cancellations. The analysis provides insights into model accuracy and its effectiveness in making cancellation predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_max_accuracy = 0\n",
    "best_x = 0\n",
    "\n",
    "for x in range(200):\n",
    "    rf = RandomForestClassifier(random_state=x)\n",
    "    rf.fit(X_train, y_train)\n",
    "    Y_pred_rf = rf.predict(X_test)\n",
    "    current_accuracy = round(accuracy_score(Y_pred_rf, y_test) * 100, 2)\n",
    "    if current_accuracy > rf_max_accuracy:\n",
    "        rf_max_accuracy = current_accuracy\n",
    "        best_x = x\n",
    "\n",
    "print(f\"Max accuracy achieved: {rf_max_accuracy}%\")\n",
    "print(f\"Best random state: {best_x}\")\n",
    "\n",
    "rf = RandomForestClassifier(random_state=best_x)\n",
    "rf.fit(X_train, y_train)\n",
    "Y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, Y_pred_rf)\n",
    "print(\"\\nConfusion Matrix for Random Forest Classifier:\")\n",
    "print(cm)\n",
    "\n",
    "plot_confusion_matrix(cm, ['Not Canceled', 'Canceled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier for Reservation Cancellation Prediction\n",
    "\n",
    "### Method Overview\n",
    "XGBoost (Extreme Gradient Boosting) Classifier is an ensemble learning method that enhances the accuracy of prediction models. It iteratively builds multiple decision trees and combines their outputs. This analysis employs XGBoost for predicting hotel reservation cancellations.\n",
    "\n",
    "### Steps Involved:\n",
    "1. **Data Encoding**:\n",
    "   - Label Encoding: Converting categorical target classes into numeric labels for training and test datasets.\n",
    "\n",
    "2. **Model Training and Prediction**:\n",
    "   - Model Fitting: Training the XGBoost Classifier using the encoded training dataset.\n",
    "   - Prediction Generation: Using the trained model to predict reservation cancellations on the encoded test dataset.\n",
    "\n",
    "3. **Evaluation**:\n",
    "   - Accuracy Computation: Calculating the accuracy score to assess the model's performance.\n",
    "   - Confusion Matrix: Generating the confusion matrix to evaluate the classification results.\n",
    "\n",
    "### Results:\n",
    "- **Accuracy Score**: Displaying the accuracy achieved by the XGBoost Classifier in predicting reservation cancellations.\n",
    "- **Confusion Matrix**: Visualization depicting the model's predictive performance through classification results.\n",
    "\n",
    "### Conclusion:\n",
    "XGBoost Classifier, an advanced boosting algorithm, is utilized to predict hotel reservation cancellations. The analysis showcases the accuracy achieved and the model's effectiveness in making accurate cancellation predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting target classes to numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# defining and fit the XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(random_state=42)\n",
    "xgb_clf.fit(X_train, y_train_encoded)\n",
    "\n",
    "# making predictions using the XGBoost model\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy_xgb = accuracy_score(y_test_encoded, y_pred_xgb) * 100\n",
    "print(f\"The accuracy score achieved using XGBoost Classifier is: {accuracy_xgb:.2f}%\")\n",
    "\n",
    "# computing confusion matrix\n",
    "cm_xgb = confusion_matrix(y_test_encoded, y_pred_xgb)\n",
    "print(\"\\nConfusion Matrix for XGBoost Classifier:\")\n",
    "print(cm_xgb)\n",
    "\n",
    "# plotting confusion matrix\n",
    "plot_confusion_matrix(cm_xgb, ['Not_Canceled', 'Canceled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Accuracy Scores from Prediction Models\n",
    "\n",
    "The following bar chart presents a visual comparison of the accuracy scores obtained from various prediction models used to predict hotel reservation cancellations. Each bar represents the accuracy score achieved by a specific prediction model. The accuracy score indicates the model's performance in correctly predicting reservation cancellations.\n",
    "\n",
    "The models evaluated include Logistic Regression, Naive Bayes, SVM with different kernels (Linear, Polynomial, and RBF), K Nearest Neighbors (KNN), Decision Tree, Random Forest, and XGBoost. Higher accuracy scores suggest better predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy scores obtained from different prediction models\n",
    "model_names = ['Logistic Regression', 'Naive Bayes', 'SVM Linear', 'SVM Polynomial', 'SVM RBF', 'KNN', 'Decision Tree', 'Random Forest', 'XGBoost']\n",
    "accuracy_scores = [lr_accuracy, nb_accuracy, svm_linear_accuracy, svm_poly_accuracy, svm_rbf_accuracy, knn_accuracy, dt_max_accuracy, rf_max_accuracy, accuracy_xgb]\n",
    "\n",
    "# Creating bar charts for accuracy scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, accuracy_scores)\n",
    "plt.xlabel('Prediction Models')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Accuracy Scores of Prediction Models')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Analysis\n",
    "\n",
    "### Logistic Regression:\n",
    "- Utilized logistic regression to predict hotel reservation cancellations with an accuracy of 81%.\n",
    "- Processed categorical data through label encoding and standardized features using StandardScaler.\n",
    "- Generated classification report and confusion matrix to evaluate model performance.\n",
    "\n",
    "### Naive Bayes:\n",
    "- Employed Gaussian Naive Bayes resulting in an accuracy of 44% for predicting reservation cancellations.\n",
    "- Generated classification report and confusion matrix to assess model predictions.\n",
    "\n",
    "### Support Vector Machine (SVM):\n",
    "- Explored SVM with linear, polynomial, and RBF kernels achieving accuracy scores ranging from 80% to 84%.\n",
    "- Evaluated classification reports and confusion matrices for each kernel to analyze performance.\n",
    "\n",
    "### K Nearest Neighbors (KNN):\n",
    "- Used KNN with an accuracy score of 84% in predicting reservation cancellations.\n",
    "- Assessed model performance using classification report and confusion matrix.\n",
    "\n",
    "### Decision Tree, Random Forest, and XGBoost:\n",
    "- Implemented Decision Tree, Random Forest, and XGBoost models achieving accuracy scores of 85.11%, 90.07%, and 89%, respectively.\n",
    "- Conducted evaluations through confusion matrices and classification reports to analyze model predictions.\n",
    "\n",
    "The analysis encompassed various machine learning algorithms to predict reservation cancellations in hotels, each demonstrating distinct accuracy levels. To enhance these models and potentially improve predictive performance, several strategies are recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies for Enhancing Prediction Models\n",
    "\n",
    "### Logistic Regression:\n",
    "- **Feature Engineering:** Explore interaction terms between variables, create dummy variables for categorical data, or try polynomial features for numeric attributes.\n",
    "- **Regularization Techniques:** Implement regularization techniques like L1 (Lasso) or L2 (Ridge) regularization to prevent overfitting.\n",
    "\n",
    "### Naive Bayes:\n",
    "- **Feature Selection:** Identify important features that significantly impact predictions. Experiment with different feature sets to observe their influence on performance.\n",
    "\n",
    "### Support Vector Machine (SVM):\n",
    "- **Hyperparameter Tuning:** Fine-tune hyperparameters such as C, gamma, and kernel coefficients to improve SVM performance further.\n",
    "- **Class Imbalance Handling:** Implement techniques like oversampling, undersampling, or using class weights to handle imbalanced classes.\n",
    "\n",
    "### K Nearest Neighbors (KNN):\n",
    "- **Feature Scaling:** Experiment with different scaling techniques to normalize or standardize features for KNN.\n",
    "- **Optimal 'k' Value:** Evaluate various values of 'k' to determine the optimal number of neighbors for classification.\n",
    "\n",
    "### Decision Tree:\n",
    "- **Pruning Techniques:** Apply pruning techniques like setting the maximum depth or minimum samples per leaf to avoid overfitting and improve generalization.\n",
    "\n",
    "### Random Forest:\n",
    "- **Ensemble Methods:** Experiment with boosting or bagging techniques by adjusting parameters like the number of trees or max depth to enhance predictive accuracy.\n",
    "- **Feature Importance:** Explore feature importance scores to understand which attributes strongly impact predictions.\n",
    "\n",
    "### XGBoost:\n",
    "- **Parameter Tuning:** Optimize hyperparameters like learning rate, tree depth, and number of estimators to enhance model performance.\n",
    "- **Regularization:** Implement regularization techniques such as L1 and L2 regularization to control overfitting.\n",
    "\n",
    "### General Enhancements:\n",
    "- **Feature Importance Analysis:** Investigate which features contribute the most to the models. Drop less important or redundant features.\n",
    "- **Address Class Imbalance:** Utilize techniques like oversampling, undersampling, or Synthetic Minority Over-sampling Technique (SMOTE) to handle imbalanced classes.\n",
    "- **Cross-Validation:** Implement cross-validation techniques to ensure robustness and validate model performance across different subsets of data.\n",
    "\n",
    "By focusing on feature engineering, hyperparameter tuning, handling class imbalance, and exploring ensemble methods, it can potentially improve the models' accuracy and robustness in predicting hotel reservation cancellations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
